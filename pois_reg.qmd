---
title: "pois_reg"
format: html
---

```{r}
library(tidyverse)
```


```{r}
#score function (DOES NOT HANDLE NULL Z APPROPRIATELY)
U <- function(beta, X, Y, Z = NULL, data) {
  
  #turn inputs into matrices
  beta <- matrix(data = beta, ncol = 1)
  data <- data.matrix(frame = data) #holds X, Z, and other potential covariates
  
  #initialize lambda, score
  if(is.null(Z)){
    l <- exp(beta[1] + beta[2] * data[, X]) 
  }
  else {
    l <- exp(beta[1] + data[, c(X, Z)] %*% beta[-1]) ## dimension n x 1
  }
  score <- matrix(data = 0, 
                  nrow = nrow(beta)) ## dimension p x 1 (where p = dim(beta))
  
  # save Y - lambda 
  yml = data[, Y] - l ## dimension n x 1
  
  #fill first element of score
  score[1] <- sum(yml)
    
  #save column copies of Y - lambda in a matrix
  ## same column, replicated once for each covariate in (X, Z)
  yml_wide <- matrix(data = yml, 
                        nrow = length(yml),
                        ncol = length(c(X, Z)), 
                        byrow = FALSE) ## dimension n x (p - 1)
  
  #fill remaining elements of score (clever way)
  score[-1] <- colSums(data[, c(X, Z)] * yml_wide)
  
  #return score
  score
}
```

```{r}
#Fisher information
info <- function(beta, X, Z = NULL, data) {
  #turn inputs into matrices
  beta <- matrix(data = beta, ncol = 1)
  data <- data.matrix(frame = data) #holds X, Z, and other potential covariates
  
  #initialize lambda
  if(is.null(Z)) {
    l <- exp(beta[1] + beta[2] * data[, X])  
  } else {
    l <- exp(beta[1] + data[, c(X,Z)] %*% beta[-1]) #dim n x 1
  }
  
  #save top left 2x2
  mini_top_left <- sum(l)
  mini_top_right <- sum(data[, X] * l)
  mini_bottom_left <- mini_top_right
  mini_bottom_right <- sum(data[,X]^2 * l)
  
  #create empty information matrix 
  i <- matrix(data = 0, 
             nrow = nrow(beta), 
             ncol = nrow(beta))
  i[1, 1] <- mini_top_left
  i[1, 2] <- i[2, 1] <- mini_bottom_left
  i[2, 2] <- mini_bottom_right 
  
  if (!is.null(Z)) {
    #extend bottom left vector (sum of product of Z and lambda)
    l_wide <- matrix(data = l, 
                     nrow = length(l),
                     ncol = length(Z), 
                     byrow = FALSE) 
    bottom_left <- colSums(data[, Z] * l_wide)
    i[-c(1:2), 1] <- bottom_left
    i[1, -c(1:2)] <- t(bottom_left)
    
    #extend bottom middle vector (sum of product of X, Z, and lambda)
    xl <- data[,X] * l
    xl_wide <- matrix(data = xl,
                      nrow = length(xl),
                      ncol = length(Z),
                      byrow = FALSE)
    bottom_middle <- colSums(data[, Z] * xl_wide)
    i[-c(1:2), 2] <- bottom_middle
    i[2, -c(1:2)] <- t(bottom_middle)
    
    #extend bottom right matrix
    #zzt <- data[, Z] %*% t(data[, Z]) #issue in dimensionality
    zz <- data[,Z] * data[,Z] #temp issue fix
    
    #l_wide <- matrix(data = l, 
                     #/nrow = length(l),
                     #ncol = ncol(zz),
                     #ncol = ncol(zzt), #same issue
                     #byrow = FALSE) 
    #bottom_right <- colSums(zzt * l_wide) #issue in dimensionality
    bottom_right <- sum(zz * l) #temp issue fix
    i[-c(1:2), -c(1:2)] <- bottom_right
  }
  return(i)
}
```

Testing the revised Info function
```{r}
beta <- c(1, 2, 3)
x <- runif(100, min = 0, max = 1)
z <- runif(100, min = 0, max = 1)
lambda <- exp(beta[1] + beta[2] * x + beta[3] * z)
y <- rpois(100, lambda)

data <- data.frame(x,z,y)
info(beta, "x", "z", data)
```

```{r}
#info <- function(beta, X, Z = NULL, data) 
#U <- function(beta, X, Y, Z = NULL, data) 

find_beta <- function(start_guess, x, y, z, data,
                      maxtol = 0.00001,
                      maxiter = 1000,
                      verbose = FALSE) {
  beta_curr <- start_guess
  diff <- maxtol + 1
  iterations <- 0
  while(diff > maxtol & iterations <= maxiter){
    beta_next <- beta_curr - solve(info(beta_curr, x, z, data)) %*% U(beta_curr, x, y, z, data)
    diff <- max(abs(beta_next - beta_curr))
    iterations <- iterations + 1
    beta_curr <- beta_next
    if(verbose) {
      print(paste("beta_next:", beta_next,"\n"))
      print(paste("diff:", diff, "\n"))
      print(paste("iterations:", iterations, "\n"))
    }
  }
  if(diff > maxtol & iterations >= maxiter){
    conv_msg = "We hit the maximum number of iterations but did not converge."
  }
  else { conv_msg = "We have achieved convergence!"}
  return(list(estimates = beta_curr,
              convergence = conv_msg))
}
```

Now, to test the simple case.
```{r}
set.seed(1031)

beta0 <- 0.5
beta1 <- 0.25
beta2 <- 0.2
x <- runif(100, min = 0, max = 1) #generate 100 rows from U(0,1)
z <- runif(100, min = 0.1, max = 1.1) #generate 100 rows from U(0.1,1.1)
lambda <- exp(beta0 + beta1*x + beta2*z)
y <- rpois(100, lambda)


my_est <- round(find_beta(start_guess = c(0.1, 0.2, 0.21), 
                          x = "x", 
                          y = "y", 
                          z = "z", 
                          data = data.frame(x,y,z))$estimates,2) 

default_est <- round(glm(y ~ x, family = "poisson")$coefficients,2)
```
```{r}
  while(diff > maxtol & iterations <= maxiter){
    beta_next <- beta_curr - solve(info(beta_curr, "x", "z", data)) %*% U(beta_curr, "x", "y", "z", data)
    diff <- max(abs(beta_next - beta_curr))
    iterations <- iterations + 1
    beta_curr <- beta_next
    if(verbose) {
      print(paste("beta_next:", beta_next,"\n"))
      print(paste("diff:", diff, "\n"))
      print(paste("iterations:", iterations, "\n"))
    }
  }
```

```{r}
set.seed(1031)
sim <- NULL
simplecase <- TRUE

for(i in 1:1000){
  beta0 <- runif(1, min = 1, max = 2)
  beta1 <- runif(1, min = 2, max = 3)
  beta2 <- runif(1, min = 3, max = 4)
  
  z <- ifelse(simplecase, 
              rep(0, times = 100), #z is zero vector
              rbinom(n = 100, size = 1, prob = 0.3)) #z ~ Bern(0.3)
  x <- runif(100, min = 0, max = 1 + z) #X|Z ~ U(0,1+Z)
  lambda <- exp(beta0 + beta1*x + beta2*z) #mean of Y|X,Z
  y <- rpois(100, lambda) #Y|X,Z ~ Pois(lambda)
  
  mine <- find_beta(c(0,0), x, y)$estimates
  default <- glm(y ~ x, family = "poisson")
  def <- c(default$coefficients[1], default$coefficients[2])
  sim <- cbind(sim, mine - def)
}


#slopes are a little over, intercepts are a little under. interesting
sim |> t() |> data.frame() |> 
  ggplot(aes(x = X1)) + 
  geom_histogram(bins = 100) +
  labs(x = "Diff",
       title = "intercept") 
sim |> t() |> data.frame() |> 
  ggplot(aes(x = X2)) + 
  geom_histogram(bins = 100) +
  labs(x = "Diff", 
       title = "slope")
```

Sim Worksheet Stuff
```{r}
error_settings <- c(1,2,3,4,5)
n_settings <- c("s","m","l")

generate_data <- function(error, n){

  set.seed(1031)
  X <- rnorm(n,0,1)
  Z <- rnorm(n,0,1)
  beta <- c(1,2,3)
  lambda <- exp(beta[1] + beta[2]*X + beta[3]*Z)
  Y <- rpois(n, lambda)
  
  if(error == 1){
    Xstar <- X
  }
  else{
    if(error == 2){
      Xstar <- X + rnorm(0,1)
    }
    else{
      if(error == 3){
        Xstar <- X + Z + rnorm(0,1)
      }
      else{
        if(error == 4){
          Xstar <- X * Z + rnorm(0,1)
        }
        else{ #error == 5
          Xstar <- X + rnorm(mean(Z) + 1)  
        }
      }
    }
  }
return(list(data = data.frame(Xstar,Y,Z), beta = beta))
  
}
```

```{r}
error_setting <- rep(0, times = 15)
n_setting <- rep("", times = 15)
bh1 <- rep(0, times = 15)
bh3 <- bh2 <- bh1
bh1SE <- rep(0, times = 15)
bh3SE <- bh2E <- bh1SE

results <- data.frame(error_setting, n_setting, 
                      bh1, bh1SE, 
                      bh2, bh2SE,
                      bh3, bh3SE)

for(error in error_settings){
  for(n in n_settings){
    df <- generate_data(error,n)
    
    guesses <- find_beta(start_guess = c(2,3,4),
              x = "Xstar",
              y = "Y",
              Z = "Z",
              data = df$data)
    #guesses$estimates gives the beta hats
    #how to fill results in the smart way?
  }
}

#plot empirical distributions
results |>
  ggplot(aes(x = bh1)) +
  geom_histogram() +
  geom_vline(xintercept = 1, color = "red")

results |>
  ggplot(aes(x = bh2)) +
  geom_histogram() +
  geom_vline(xintercept = 2, color = "red")

results |>
  ggplot(aes(x = bh3)) +
  geom_histogram() +
  geom_vline(xintercept = 1, color = "red")

#show means of parameter estimates
mean(results$bh1)
mean(results$bh2)
mean(results$bh3)

#show means of SE estimates
mean(results$bh1SE)
mean(results$bh2SE)
mean(results$bh3SE)


```
