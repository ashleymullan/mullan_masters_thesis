---
title: "pois_reg"
format: html
---

```{r}
library(tidyverse)
```

TO DO: update information, update find_beta, extend sim


U(beta = c(0.5, 0.25, 0.1), 
  Y = "y", 
  X = "x", 
  Z = "z", 
  data = dat)

```{r}
#score function (DOES NOT HANDLE NULL Z APPROPRIATELY)
U <- function(beta, X, Y, Z = NULL, data) {
  
  #turn inputs into matrices
  beta <- matrix(data = beta, ncol = 1)
  data <- data.matrix(frame = data) #holds X, Z, and other potential covariates
  
  #initialize lambda, score
  if(is.null(Z)){
    l <- exp(beta[1] + beta[2] * data[, X]) 
  }
  else {
    l <- exp(beta[1] + data[, c(X, Z)] %*% beta[-1]) ## dimension n x 1
  }
  score <- matrix(data = 0, 
                  nrow = nrow(beta)) ## dimension p x 1 (where p = dim(beta))
  
  # save Y - lambda 
  yml = data[, Y] - l ## dimension n x 1
  
  #fill first element of score
  score[1] <- sum(yml)
    
  #save column copies of Y - lambda in a matrix
  ## same column, replicated once for each covariate in (X, Z)
  yml_wide <- matrix(data = yml, 
                        nrow = length(yml),
                        ncol = length(c(X, Z)), 
                        byrow = FALSE) ## dimension n x (p - 1)
  
  #fill remaining elements of score (clever way)
  score[-1] <- colSums(data[, c(X, Z)] * yml_wide)
  
  #return score
  score
}

#Fisher information
info <- function(beta, X, Z = NULL, data) {
  out <- list()
  #turn inputs into matrices
  beta <- matrix(data = beta, ncol = 1)
  data <- data.matrix(frame = data) #holds X, Z, and other potential covariates
  
  #initialize lambda
  if(is.null(Z)) {
    l <- exp(beta[1] + beta[2] * data[, X])  
  }
  else {
    l <- exp(beta[1] + data[, c(X,Z)] %>% beta[-1]) #dim n x 1
  }
  
  
  #save top left 2x2
  mini_top_left <- sum(l)
  mini_top_right <- sum(data[, X] * l)
  mini_bottom_left <- mini_top_right
  mini_bottom_right <- sum(data[,X]^2 * l)
  
  #extend bottom left vector (sum of product of Z and lambda)
  l_wide <- matrix(data = l, 
                        nrow = length(l),
                        ncol = length(Z), 
                        byrow = FALSE) 
  #bottom_left <- colSums(data[, Z] * l_wide)
  bottom_left <- "WRONG"
  
  #extend bottom middle vector (sum of product of X, Z, and lambda)
  xl <- data[,X] * l
  xl_wide <- matrix(data = xl,
                    nrow = length(xl),
                    ncol = length(Z),
                    byrow = FALSE)
  bottom_middle <- colSums(data[, Z] * xl_wide)
  
  #extend bottom right matrix
  zzt <- data[, Z] %*% t(data[, Z])
  bottom_right <- "WRONG"
  #bottom_right <- colSums(zzt * l_wide)
  
  
  
  out$mtl <- mini_top_left
  out$mtr <- mini_top_right
  out$mbl <- mini_bottom_left
  out$mbr <- mini_bottom_right
  
  out$bl <- bottom_left
  out$bm <- bottom_middle
  out$br <- bottom_right
  
  out
}
```

Testing the revised Info function
```{r}
beta <- c(1, 2, 3)
x <- runif(100, min = 0, max = 1)
z <- runif(100, min = 0, max = 1)
lambda <- exp(beta[1] + beta[2] * x + beta[3] * z)
y <- rpois(100, lambda)

data <- data.frame(x,z,y)
info(beta, "x", "z", data)

```



```{r}
#info <- function(beta, X, Z = NULL, data) 
#U <- function(beta, X, Y, Z = NULL, data) 

find_beta <- function(start_guess, x, y, z, data,
                      maxtol = 0.00001,
                      maxiter = 1000,
                      verbose = FALSE) {
  beta_curr <- start_guess
  diff <- maxtol + 1
  iterations <- 0
  while(diff > maxtol & iterations <= maxiter){
    beta_next <- beta_curr - solve(info(beta_curr, x, z, data)) %*% U(beta_curr, x, y, z, data)
    diff <- max(abs(beta_next[1] - beta_curr[1]), abs(beta_next[2] - beta_curr[2]))
    iterations <- iterations + 1
    beta_curr <- beta_next
    if(verbose) {
      print(paste("beta_next:", beta_next,"\n"))
      print(paste("diff:", diff, "\n"))
      print(paste("iterations:", iterations, "\n"))
    }
  }
  if(diff > maxtol & iterations >= maxiter){
    conv_msg = "We hit the maximum number of iterations but did not converge."
  }
  else { conv_msg = "We have achieved convergence!"}
  return(list(estimates = beta_curr,
              convergence = conv_msg))
}
```

Now, to test the simple case.
```{r}
set.seed(1031)

beta0 <- 0.5
beta1 <- 0.25
x <- runif(100, min = 0, max = 1) #generate 100 rows from U(0,1)
lambda <- exp(beta0 + beta1*x)
y <- rpois(100, lambda)

my_est <- round(find_beta(start_guess = c(0,0), 
                          x = x, 
                          y = y, 
                          z = NULL, 
                          data = data.frame(x,y,z))$estimates,2) 

default_est <- round(glm(y ~ x, family = "poisson")$coefficients,2)

```

```{r}
set.seed(1031)
sim <- NULL
simplecase <- TRUE

for(i in 1:1000){
  beta0 <- runif(1, min = 1, max = 2)
  beta1 <- runif(1, min = 2, max = 3)
  beta2 <- runif(1, min = 3, max = 4)
  
  z <- ifelse(simplecase, 
              rep(0, times = 100), #z is zero vector
              rbinom(n = 100, size = 1, prob = 0.3)) #z ~ Bern(0.3)
  x <- runif(100, min = 0, max = 1 + z) #X|Z ~ U(0,1+Z)
  lambda <- exp(beta0 + beta1*x + beta2*z) #mean of Y|X,Z
  y <- rpois(100, lambda) #Y|X,Z ~ Pois(lambda)
  
  mine <- find_beta(c(0,0), x, y)$estimates
  default <- glm(y ~ x, family = "poisson")
  def <- c(default$coefficients[1], default$coefficients[2])
  sim <- cbind(sim, mine - def)
}


#slopes are a little over, intercepts are a little under. interesting
sim |> t() |> data.frame() |> 
  ggplot(aes(x = X1)) + 
  geom_histogram(bins = 100) +
  labs(x = "Diff",
       title = "intercept") 
sim |> t() |> data.frame() |> 
  ggplot(aes(x = X2)) + 
  geom_histogram(bins = 100) +
  labs(x = "Diff", 
       title = "slope")
```

